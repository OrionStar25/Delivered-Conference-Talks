Question,Option1,Option2,Option3,Option4,Option5,Option6,CorrectAnswerOption,Explanation
<p>How does Retrieval Augmented Generation (RAG) differentiate from a general-purpose chat system in answering specific questions about a workplace?</p>,Using RAG and general-purpose chat systems will provide the same performance.,RAG requires changing the model weights of LLMs to answer specific questions about a workplace.,"RAG provides the LLM with additional knowledge specific to the workplace, allowing it to generate more informed and contextually relevant responses to questions about the workplace. ","General chat systems provide the LLM with additional knowledge specific to the workplace, allowing it to generate more informed and contextually relevant responses to questions about the workplace. ",,,3,
"""LLM A"" is the best-performing LLM in the world. We create a RAG system with ""LLM A"". We use the same ""LLM A"" to evaluate this RAG system. This is a valid approach since we should always evaluate with the best available LLM.",True,False,,,,,2,
"In a RAG system, the LLM reduces hallucination by learning the knowledge base of the domain-specific data.",True,False,,,,,2,
"<p>What is the best way of evaluating a RAG system?&nbsp;</p><p>""$gt;"" means ""&gt;"" (greater than)</p>",LLMs $gt; Traditional NLP Metrics $gt; Humans,LLMs ~= Traditional NLP Metrics $gt; Humans,Humans $gt; Traditional NLP Metrics $gt; LLMs,Humans $gt; Traditional NLP Metrics ~= LLMs,,,4,
"What does it mean when a RAG system has a high ""Groundedness"" score?",The retrieved contexts is supported by the query asked by the user.,The generated answer is supported by the context provided during prompting.,The generated answer is relevant to the query asked by the user.,The generated answer is very similar to the ground truth.,,,2,
What is the best way to create an evaluation dataset of a huge knowledge base with multiple sections?,Build a set of ~100+ questions all belonging to the same section.,Build a set of 20 questions covering all the different sections.  ,Build a set of ~100+ questions covering all the different sections.,Build a set of 20 questions all belonging to the same section.,,,3,
What is the role of a Reranker in a RAG system?,It ranks the retrieved contexts and selects the most relevant contexts to provide to the LLM. ,It generates new contexts for the LLM by reranking the knowledge base.,It ranks the generated answers by the LLM and outputs the best answer.,It retrieves initial context from the knowledge base using the query. ,,,1,
"The RAG Triad consists of Answer relevance, Context relevance, and Groundedness.",True,False,,,,,1,
What is the use of Chain-of-thought (COT) Prompting in an LLM?,It has the same use as normal prompting techniques.,It only enables the LLM to give reasons for its answer before arriving at the actual answer. ,It only helps in debugging LLM outputs.,It enables the LLM to think and give reasons for its answer before arriving at the actual answer. It also helps in debugging LLM outputs.,,,4,
What is the easiest way to tune a RAG system?,Tune the chunk size while creating the vector database.,Use better text embeddings.,Use a reranker.,Use a better LLM.,,,1,
